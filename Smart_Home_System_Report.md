# **智慧家庭系統整合專案書面報告**

## **一、方案構思 \- 解決各項目問題預計使用的技術**

### **1\. 專案背景與目標**

本專案旨在建構一套運行於 **NVIDIA Jetson TX2** 邊緣運算裝置上的完整智慧家庭系統。系統需整合物聯網感測器、影像監控、AI 語音控制以及底層核心驅動程式，並透過跨平台客戶端進行遠端管理，解決傳統智慧家庭系統通訊協定分散及安全性不足的問題。

### **2\. 問題分析與技術解決方案**

| 項目問題 | 解決方案與技術選型 | 技術細節 |
| :---- | :---- | :---- |
| **跨平台控制介面** | **Avalonia UI (.NET)** | 使用 Avalonia 框架開發客戶端，單一程式碼庫即可同時支援 Windows Desktop 與 Android 行動裝置，解決不同裝置間的 UI 適配問題。 |
| **異質網路整合** | **MQTT \+ Python Bridge** | 針對 WiFi 節點使用 MQTT 協定；針對無 WiFi 環境的藍牙節點，開發 Python 橋接器將 RFCOMM 訊號轉發至 MQTT Broker，實現統一通訊介面。 |
| **系統安全性日誌** | **Linux Kernel Module** | 為了防止日誌被輕易竄改，不使用一般檔案寫入，而是撰寫 Linux 字元驅動程式 (/dev/blackbox)，透過 ioctl 系統呼叫將關鍵操作紀錄於核心記憶體中。 |
| **環境感知與自動化** | **ESP32 \+ ASP.NET Core** | 伺服器端採用 ASP.NET Core 處理邏輯，配合 ESP32 節點的 BME280 感測器。例如：當濕度過高時，ESP32 直接觸發 Relay 開啟除濕設備。 |
| **影像辨識與AI控制** | **OpenCV \+ Gemini API** | 利用 TX2 的運算能力執行 OpenCV 人臉偵測 (Smart Away 功能)，並整合 Google Gemini API 進行自然語言指令解析 (如：「幫我打開客廳的燈」)。 |
| **部署與移植性** | **Docker Container** | 將伺服器環境容器化，解決 OpenCV 與 .NET Runtime 在嵌入式系統上的相依性問題，並使用 \--privileged 模式存取硬體。 |

## **二、實驗步驟 \- 詳細描述各項目實作過程**

### **步驟 1：硬體搭建與環境配置**

首先配置 Jetson TX2 作為中控主機，並連接周邊硬體。

1. **GPIO 與 LED 配置**：將 LED 連接至 TX2 的 GPIO 腳位 (396, 466, 397, 255, 388)，用於狀態指示。  
2. **SPI 介面配置**：啟用 TX2 的 /dev/spidev3.0，連接 MCP3008 ADC 晶片與光敏電阻，讀取環境亮度(CH 0)。  
3. **感測節點組裝**：將 BME280、OLED 面板與 Relay 接至 ESP32 開發板。

### **步驟 2：Linux 核心驅動程式開發 (Blackbox Driver)**

為了實作高安全性的日誌系統，我們開發了一個 Linux Kernel Module。

1. **撰寫驅動程式 (blackbox\_driver.c)**：定義 file\_operations 結構，實作 open, read (讀取日誌), ioctl (寫入日誌)。  
2. **記憶體管理**：使用 kmalloc 分配核心空間的環形緩衝區 (Circular Buffer) 來儲存帳號密碼驗證紀錄。  
3. **編譯與載入**：使用 Makefile 針對 TX2 的核心版本進行編譯，產生 .ko 檔並掛載。  
   make  
   make load

### **步驟 3：後端伺服器建置 (SmartHomeServer)**

使用 ASP.NET Core 建置核心服務。

1. **硬體服務層 (HardwareManager.cs)**：透過 System.Device.Gpio 與 SysFs 控制 LED 與 PWM 風扇轉速。  
2. **通訊服務**：  
   * \*\*SignalR：\*\*建立 SensorHub，將感測數據即時推播至前端。  
   * \*\*MQTT Service：\*\*訂閱 home/sensor/\# 主題，接收 ESP32 數據。  
   * \*\*Bluetooth Service：\*\*利用藍牙與ESP32溝通  
3. **影像服務**：整合 CameraService.cs 擷取影像串流，並利用DNN模型進行人臉辨識。  
4. **AI 與**：加入 Gemini API 進行指令解析，讓使用者可以利用自然語言與系統溝通。  
5. **Docker 部署**：撰寫 Dockerfile，以 ARM64 架構建置映像檔，並掛載 /dev 目錄以存取驅動程式與硬體。

### **步驟 4：邊緣節點與橋接器開發**

1. **MQTT 節點 (Living Room)**：撰寫 Arduino 程式，讀取 BME280 數值。加入自動化邏輯：若濕度 \> 75% 則觸發 Relay (模擬除濕機開啟)。  
2. **藍牙節點 (Remote Unit)**：透過 BluetoothSerial 廣播感測數據。  
3. **藍牙橋接器 (bt\_bridge.py)**：在 TX2 上運行 Python 腳本，透過 RFCOMM 連接藍牙節點，收到數據後轉發至 MQTT Broker，實現協定轉換。

### **步驟 5：跨平台客戶端開發 (SmartHomeClient)**

使用 Avalonia UI 開發圖形介面。

1. **儀表板設計**：設計 Dashboard 頁面，透過 SignalR 接收即時溫濕度與光照數據。  
2. **影像監控與控制**：實作 MJPEG 串流播放器，並加入 LED 控制開關。  
3. **黑盒子存取**：設計登入介面，驗證成功後呼叫後端 API，將紀錄寫入核心驅動，並顯示回傳的日誌。  
4. **Android 支援**：調整 UI Layout 以適配手機螢幕，並處理 Android 權限設定。

## **三、專案心得**

### **遇到的困難與技術反思**

本次專案是一趟充滿挑戰但也極具啟發性的技術旅程。在實作過程中，我深刻體會到將理論轉化為實際系統時所面臨的種種細節問題，特別是在嵌入式系統與現代化軟體架構的整合上。

首先是 **Docker 容器化部署與硬體權限** 的衝突。起初我天真地認為只需將 .NET 程式打包即可，卻忽略了 Linux 核心對於硬體資源的嚴格管控。當程式在容器內拋出「Access Denied」或是找不到裝置節點的錯誤時，我花費了大量時間研究 Linux 的 Namespace 與 Cgroup 機制。我了解到容器的本質是隔離，而物聯網應用的本質卻是連接。為了解決這個矛盾，我深入學習了 \--privileged 模式的運作原理，以及如何透過 Volume Mapping (-v /dev:/dev) 精準地將主機的硬體介面暴露給容器。這不只是修復了一個 Bug，更讓我對作業系統的權限模型有了具象的認識。

其次，**Linux Kernel Driver 開發** 是一項艱鉅的挑戰。Jetson TX2 搭載的 4.9 版本核心相對老舊，這成為了一大門檻。網路上許多的 Kernel Module 教學或範例程式碼都基於較新的 5.x 甚至 6.x 版本核心，許多 API (例如記憶體存取函數 copy\_to\_user 的細微變化或是時間結構體 timespec 的定義) 都已經發生了變革。我必須像考古學家一樣，翻閱舊版的 Linux 核心源碼樹，仔細比對標頭檔的定義差異，才能寫出能成功編譯且不會導致 Kernel Panic 的穩定程式碼。這個過程極度考驗耐心，但也讓我學會了如何使用 dmesg 追蹤除錯，並對 User Space 與 Kernel Space 之間的資料交換機制有了深刻理解。

再者，**跨平台開發的理想與現實** 也是一大課題。Avalonia UI 雖然提供了強大的跨平台能力，但在整合 OpenCV 這類需要呼叫底層原生 C++ 函式庫的功能時，ARM64 架構與 Android 系統的特殊性帶來了依賴地獄 (Dependency Hell)。我必須手動處理 NuGet 套件在不同 runtime identifier (RID) 下的載入行為，甚至需要針對 Android 的檔案系統權限進行額外設定，才能讓影像串流順暢運作。這讓我明白，所謂的「跨平台」往往建立在對各平台底層特性的深入了解之上，而非單純的依賴高階工具。

### **專案整合感想與未來展望**

儘管過程充滿荊棘，但這些困難最終都轉化為 **系統整合成功時的巨大成就感**。當我第一次對著手機 App 說出「開啟警示模式」，聲音訊號經由 WiFi 傳到 ASP.NET Core 伺服器，經過 Gemini AI 的 LLM 模型解析意圖，再透過 SignalR 廣播給前端，同時驅動底層 Driver 寫入安全日誌，並觸發 LED 閃爍時，那種「數據在流動」的感覺非常震撼。這不單單是寫程式，而是賦予了分散的硬體一個統一的「大腦」。

此外，**AI 的導入** 更是本專案的亮點。傳統 IoT 控制依賴僵化的指令或實體按鈕，而整合 LLM 後，系統具備了模糊語意理解的能力。這讓我看見了未來智慧家庭的雛形：不再是人去適應機器的開關，而是機器透過 AI 去理解人的自然語言與需求。

總結來說，這個專案讓我從一名單純的軟體開發者，蛻變為能夠綜觀全局的系統整合者。我學會了如何在資源受限的嵌入式環境中優化效能，如何在底層驅動的穩定性與上層應用的靈活性之間取得平衡。從底層的 C 語言指標操作，到中層的 Docker 容器管理，再到上層的 C\# 非同步程式設計與 AI API 串接，這段經歷不僅磨練了我的技術硬實力，更培養了我面對未知錯誤時的分析與解決問題的能力，為未來的研發之路打下了堅實基礎。

## 

